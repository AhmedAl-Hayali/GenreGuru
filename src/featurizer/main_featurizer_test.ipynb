{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"imports\"\"\"\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spotify authentication'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"spotify authentication\"\"\"\n",
    "# import tomllib\n",
    "# import spotipy\n",
    "# from spotipy.oauth2 import SpotifyClientCredentials\n",
    "# with open(\"cfg.toml\", \"rb\") as cfg:\n",
    "#     keys = tomllib.load(cfg)[\"spotify\"]\n",
    "#     c_id = keys[\"client_id\"]\n",
    "#     c_secret = keys[\"client_secret\"]\n",
    "#     auth_manager = SpotifyClientCredentials(client_id=c_id, client_secret=c_secret)\n",
    "    \n",
    "# sp = spotipy.Spotify(auth_manager=auth_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Old Input Loaders'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Old Input Loaders\"\"\"\n",
    "# def downsampleAudio(audio_file_path, target_sample_rate=16000):\n",
    "#     #load the audio and downsample it. \n",
    "#     #librosa.load converts the audio file input (.wav, preferrably) into a time series. \n",
    "#     signal, sampling_rate = librosa.load(audio_file_path, sr=target_sample_rate, mono=True)\n",
    "#     #normalize amplitude of the audio signal\n",
    "#     signal = signal / np.max(np.abs(signal))\n",
    "#     return signal, sampling_rate\n",
    "\n",
    "# #draft preprocessor module. Downsamples and STFTs the audio. \n",
    "# def processAudio(audio_file_path):\n",
    "#     signal, sampling_rate = downsampleAudio(audio_file_path)\n",
    "#     #stft signal for feature computation\n",
    "#     stft_signal = librosa.stft(signal, window='hann')\n",
    "#     return signal, stft_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'original RMS and dynamic range compute, operated over the entire signal.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"original RMS and dynamic range compute, operated over the entire signal.\"\"\"\n",
    "# def computeRMS(signal):\n",
    "#     #RMS is the square root of the average of the squared signal. \n",
    "#     squared_signal = np.square(signal)\n",
    "#     mean_squared = np.mean(squared_signal)\n",
    "#     rms = np.sqrt(mean_squared)\n",
    "#     #convert RMS to decibels\n",
    "#     rms = 20*np.log10(rms)\n",
    "#     return rms\n",
    "\n",
    "# def computeDynamicRange(signal, rms):\n",
    "#     #Dynamic range here is defined as peak - RMS, as peak - min would yield the max. \n",
    "#     #decibel conversion in order to avoid computing division, as that ends up being slower. \n",
    "#     max_level = 20 *np.log10(np.max(np.abs(signal)))\n",
    "#     dynamic_range = max_level - rms\n",
    "#     return dynamic_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"spectrogram plotter for testing\"\"\"\n",
    "def plotSpectrogram(stft_signal, target_sampling_rate):\n",
    "    #adapted from @baleanu\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    #compute the spectrogram power, then to dB\n",
    "    power_spectrogram = np.abs(stft_signal)**2\n",
    "    spectrogram_db = librosa.amplitude_to_db(power_spectrogram, ref=np.max)\n",
    "\n",
    "    #display spectrogram\n",
    "    librosa.display.specshow(spectrogram_db, sr = target_sampling_rate, x_axis='time', y_axis='linear', cmap='viridis')\n",
    "    plt.colorbar(label='Power (dB)')\n",
    "    plt.title('Power Spectrogram')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.show()\n",
    "    print(stft_signal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"audio processor\n",
    "taken from matthew baleanu and Mohamad-Hassan Bahsoun\n",
    "16khz downsample (default 22.05khz, spotify audio is 44.1khz.)\n",
    "default sampling rate set to 16khz as per @bahsoun\"\"\"\n",
    "def processAudio(audio_file_path, target_sample_rate=16000):\n",
    "    \"\"\"load the audio and sample it at the target rate. \n",
    "    librosa.load converts the audio file into a time series at the desired sampling rate \"\"\"\n",
    "    signal, sampling_rate = librosa.load(audio_file_path, sr=target_sample_rate, mono=True)\n",
    "    \"\"\"normalize the amplitude of the signal.\"\"\"\n",
    "    signal = signal / np.max(np.abs(signal))\n",
    "    \"\"\"stft signal for feature computation. probably will be moved. \"\"\"\n",
    "    stft_signal = librosa.stft(signal, window='hann')\n",
    "    return signal, stft_signal, sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Signal Divider Based on BPM\n",
    "    as suggested by MVM, the signal we divide up the signal into bins and compute a window size in order to get\n",
    "    variance for our feature, this way we can determine how relevant they would be for classification/recommendation.\"\"\"\n",
    "def divideSignal(signal, bpm, sampling_rate, beats_per_win = 4):\n",
    "    \"\"\"process is as such:\n",
    "    1. get global tempo (bpm)\n",
    "    2. convert that to beat segments\n",
    "    3. use it to divide up the song.\"\"\"\n",
    "    beat_duration = 60/bpm\n",
    "    song_length_seconds = len(signal)/sampling_rate\n",
    "    beat_count = song_length_seconds/beat_duration\n",
    "    \n",
    "    \"\"\"once beat count is computed, compute the window size as a fixed multiple of the beat count\n",
    "    Round up division on beat_count/beats_per_win to compute the window count. \n",
    "    To calculate the window size: the length of the signal is seconds * samples, as that is an audio time series. The window size would \n",
    "    therefore be the sample length of len(signal)/window_count rounded up, in order to contain all samples.\"\"\"\n",
    "    window_count = int(np.ceil(beat_count/beats_per_win))\n",
    "    window_size = int(np.ceil(len(signal)/window_count))\n",
    "    \n",
    "    \"\"\"to divide the signal we pad the original signal with zeroes at the end until it is of the proper length\n",
    "    for consistency and then reshape it.\"\"\"\n",
    "    \n",
    "    divided_signal = np.pad(signal,\n",
    "                            (0, window_count*window_size-len(signal)),\n",
    "                            mode=\"constant\",\n",
    "                            constant_values=0)\n",
    "    \n",
    "    \"\"\"now we must reshape the signal.\"\"\"\n",
    "    divided_signal = divided_signal.reshape(window_count, window_size)\n",
    "    return divided_signal, window_size, window_count\n",
    "\n",
    "\"\"\"need to STFT invidual pieces\"\"\"\n",
    "def divideSTFT(divided_signal):\n",
    "    \"\"\"sample STFT calculation is necessary in order to perform preallocation for efficiency\"\"\"\n",
    "    x, y = librosa.stft(divided_signal[0]).shape\n",
    "    divided_stft_signal = np.zeros((divided_signal.shape[0], x, y), dtype=np.complex128)\n",
    "    divided_stft_magnitudes = np.zeros((divided_signal.shape[0], x, y))\n",
    "    for i in range(divided_signal.shape[0]): \n",
    "        stft_slice = librosa.stft(divided_signal[i])\n",
    "        divided_stft_signal[i] = stft_slice\n",
    "        divided_stft_magnitudes[i] = np.abs(stft_slice)\n",
    "\n",
    "    return divided_stft_signal, divided_stft_magnitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Temporary BPM compute\"\"\"\n",
    "def computeBPM(signal, target_sample_rate):\n",
    "    \"\"\"temporary BPM calculation is simply done as librosa.feature.bpm. \n",
    "    this is because @baleanu code has not been updated to same branch, \n",
    "    and testing of the window division based on BPM relies on this module\n",
    "    this is to be replaced with the real computeBPM function, already implementedby @baleanu\"\"\"\n",
    "    bpm = librosa.feature.tempo(y=signal, sr=target_sample_rate)\n",
    "    return bpm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"RMS compute, operates over divided signal\n",
    "computes rms over each window, return vector of rms values and average rms\"\"\"\n",
    "def computeRMS(divided_signal):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        divided_signal: 3-dimensional ndarray of STFT'd signals (2-dimensional)\n",
    "    returns: \n",
    "        rms: ndarray of RMS values for each window, \n",
    "        rms_mean: average RMS value of rms\n",
    "    \"\"\"\n",
    "    rms = np.zeros((divided_signal.shape[0], 1))\n",
    "    rms_mean = 0\n",
    "    for i in range(divided_signal.shape[0]):\n",
    "        squared_signal = np.square(divided_signal[i])\n",
    "        mean_squared = np.mean(squared_signal)\n",
    "        root_mean_squared = np.sqrt(mean_squared)\n",
    "        \"decibel conversion of the rms portion\"\n",
    "        root_mean_squared = 20*np.log10(root_mean_squared)\n",
    "        rms_mean += root_mean_squared\n",
    "        rms[i] = root_mean_squared\n",
    "    \"\"\"variance calculation\"\"\" \n",
    "    rms_mean /= divided_signal.shape[0]\n",
    "    return rms, rms_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"divided dynamic range compute\n",
    "Computes the Dynammic range in each window of the signal\"\"\"\n",
    "def computeDynamicRange(divided_signal, divided_rms):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        divided_signal: 3-dimensional ndarray of STFT'd signals (2-dimensional)\n",
    "    returns: \n",
    "        dynamic_range: ndarray of RMS values for each window, \n",
    "        dynamic_range_mean: average value of dynamic_range\n",
    "    \"\"\"\n",
    "    dynamic_range = np.zeros((divided_signal.shape[0], 1))\n",
    "    dynamic_range_mean = 0\n",
    "    for i in range(divided_signal.shape[0]):\n",
    "        dynamic_max = 20 *np.log10(np.max(np.abs(divided_signal[i])))\n",
    "        dynamic_range_slice = dynamic_max - divided_rms[i]\n",
    "        dynamic_range[i] = dynamic_range_slice\n",
    "        dynamic_range_mean += dynamic_range_slice\n",
    "    dynamic_range_mean /= divided_signal.shape[0]\n",
    "    return dynamic_range, dynamic_range_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"spectral centroid 1: averaged spectral centroid compute\"\"\"\n",
    "\n",
    "\"\"\"define a helper function for getSpectralCentroid\"\"\"\n",
    "def computeSpectralCentroid(stft_signal, frequencies):\n",
    "    # compute the magnitude of the stft\n",
    "    x_n = stft_signal\n",
    "    f_n = frequencies[:,None]\n",
    "   \n",
    "    # multiply each frequency bin by the magnitude\n",
    "    # Centroid = (Σₙ₌₀ᴺ⁻¹ [f(n) * x(n)]) / (Σₙ₌₀ᴺ⁻¹ x(n))\n",
    "    numerator = np.sum(f_n * x_n)\n",
    "    denominator = np.sum(x_n)\n",
    "\n",
    "    #if x(n)s are zero for some reason\n",
    "    epsilon = 1e-6\n",
    "    denominator = np.where(denominator==0, epsilon, denominator)\n",
    "    \n",
    "    spec_c = numerator/denominator\n",
    "    # print(f\"{spec_c.shape}\")\n",
    "    return spec_c\n",
    "\n",
    "\"\"\" spectral centroid code adapted from @bahsoun\"\"\"\n",
    "def computeSpectralCentroidsMean(divided_stft_magnitudes, sampling_rate):\n",
    "    \"\"\"spectral centroic calc is: Centroid = (Σₙ₌₀ᴺ⁻¹ [f(n) * x(n)]) / (Σₙ₌₀ᴺ⁻¹ x(n))\n",
    "    np.fft.rfftfreq conputes f(n), need to compute spectral centroid over window in each piece of the signal\n",
    "    divided_stft_magnitudes contains the magnitudes the divided signal after each piece has been passed through STFT\"\"\"\n",
    "    frequencies = np.fft.rfftfreq(2048, d=1/sampling_rate)\n",
    "    spectral_centroids = np.zeros((divided_stft_magnitudes.shape[0], 1))\n",
    "    # spectral_centroids = np.zeros((divided_stft_magnitudes.shape[0], computeSpectralCentroid(divided_stft_magnitudes[0], frequencies).shape[0]))\n",
    "    mean_spectral_centroid = 0\n",
    "    for i in range(divided_stft_magnitudes.shape[0]):\n",
    "        \"\"\"np.mean in order to average the spectral centroid over the window.\"\"\"\n",
    "        spectral_centroid_piece = computeSpectralCentroid(divided_stft_magnitudes[i], frequencies)\n",
    "        spectral_centroids[i] = spectral_centroid_piece\n",
    "        mean_spectral_centroid += spectral_centroid_piece\n",
    "    mean_spectral_centroid /= divided_stft_magnitudes.shape[0]\n",
    "    return spectral_centroids, mean_spectral_centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"spectral centroid 2: computed centroid at each sampling frame\"\"\"\n",
    "\"\"\"define a helper function for getSpectralCentroid\"\"\"\n",
    "def computeSpectralCentroid(stft_signal_mag, frequencies):\n",
    "    \"\"\"Computes the spectral centroid for each sampling frame contained in the window.\n",
    "    parameters:\n",
    "        stft_signal_mag: 2D numpy array containing magnitude of a signal window's STFT \n",
    "        frequencies: frequencies at the sampling rate and window size\n",
    "    returns:\n",
    "        spec_c: spectral centroid values at each sampling frame of the signal window's STFT. \"\"\"\n",
    "    # compute the magnitude of the stft\n",
    "    x_n = stft_signal_mag\n",
    "    f_n = frequencies[:,None]\n",
    "   \n",
    "    # multiply each frequency bin by the magnitude\n",
    "    # Centroid = (Σₙ₌₀ᴺ⁻¹ [f(n) * x(n)]) / (Σₙ₌₀ᴺ⁻¹ x(n))\n",
    "    numerator = np.sum(f_n * x_n, axis = 0)\n",
    "    denominator = np.sum(x_n, axis = 0)\n",
    "\n",
    "    #if x(n)s are zero for some reason\n",
    "    epsilon = 1e-6\n",
    "    denominator = np.where(denominator==0, epsilon, denominator)\n",
    "    \n",
    "    spec_c = numerator/denominator\n",
    "    # print(f\"{spec_c.shape}\")\n",
    "    return spec_c\n",
    "\n",
    "\"\"\" spectral centroid code adapted from @bahsoun\"\"\"\n",
    "def computeSpectralCentroidsMean(divided_stft_magnitudes, sampling_rate):\n",
    "    \"\"\"spectral centroic calc is: Centroid = (Σₙ₌₀ᴺ⁻¹ [f(n) * x(n)]) / (Σₙ₌₀ᴺ⁻¹ x(n))\n",
    "    np.fft.rfftfreq conputes f(n), need to compute spectral centroid over window in each piece of the signal\n",
    "    parameters:\n",
    "        divided_stft_magnitudes: 3D ndarray containing all the windows of signal's STFT magnitude values\n",
    "        sampling_rate: integer, sampling rate\n",
    "    returns:\n",
    "        spectral_centroids: ndarray of the spectral centroid at each frame for a track window\n",
    "        total_mean_spectral_centroids: float, the average of all spectral centroids over the entire track \n",
    "        mean_spectral_centroids: ndarray mean of the spectral centroid for each track window. Contains the mean of spectral_centroids\"\"\"\n",
    "    frequencies = np.fft.rfftfreq(2048, d=1/sampling_rate)\n",
    "    spectral_centroids = np.zeros((divided_stft_magnitudes.shape[0], computeSpectralCentroid(divided_stft_magnitudes[0], frequencies).shape[0]))\n",
    "    total_mean_spectral_centroid = 0\n",
    "    mean_spectral_centroids = np.zeros((divided_stft_magnitudes.shape[0],1))\n",
    "    for i in range(divided_stft_magnitudes.shape[0]):\n",
    "        \"\"\"np.mean in order to average the spectral centroid over the window.\"\"\"\n",
    "        spectral_centroid_piece = computeSpectralCentroid(divided_stft_magnitudes[i], frequencies)\n",
    "        spectral_centroids[i] = spectral_centroid_piece\n",
    "        mean_spectral_centroid_slice = np.mean(spectral_centroid_piece)\n",
    "        total_mean_spectral_centroid += mean_spectral_centroid_slice\n",
    "        mean_spectral_centroids[i] = mean_spectral_centroid_slice\n",
    "        \n",
    "    total_mean_spectral_centroid /= divided_stft_magnitudes.shape[0]\n",
    "    return spectral_centroids, total_mean_spectral_centroid, mean_spectral_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"method 2 spectral rolloff compute testing\"\"\"\n",
    "def computeSpectralRolloffFrequency(stft_magnitude, frequencies, percentile):\n",
    "    \"\"\"Compute the spectral rolloff frequency for each time frame in the STFT.\n",
    "    Parameters:\n",
    "        stft_magnitude (np.ndarray): Magnitude of STFT\n",
    "        frequencies: frequencies at the sampling rate and window size\n",
    "        percentile (float): Energy threshold (e.g., 85, 95) to define rolloff.\n",
    "    Returns: \n",
    "        np.ndarray: Rolloff frequencies for each time frame (shape: time_frames).\"\"\"\n",
    "    # Compute frequency bins (assuming n_fft=2048 as in your example)\n",
    "    \n",
    "    # Total energy per time frame (sum across frequency bins)\n",
    "    total_energy = np.sum(stft_magnitude, axis=0)\n",
    "    \n",
    "    # Threshold energy for each time frame (percentile of total energy)\n",
    "    threshold = total_energy * percentile\n",
    "    \n",
    "    # Cumulative energy along frequency bins (axis=0)\n",
    "    cumulative_energy = np.cumsum(stft_magnitude, axis=0)\n",
    "    \n",
    "    # Find the first frequency bin where cumulative energy >= threshold\n",
    "    mask = cumulative_energy >= threshold\n",
    "    rolloff_indices = np.argmax(mask, axis=0)\n",
    "    \n",
    "    # Handle cases where threshold is never met (use highest frequency)\n",
    "    rolloff_indices = np.where(np.any(mask, axis=0), rolloff_indices, len(frequencies) - 1)\n",
    "\n",
    "    # Get corresponding frequencies\n",
    "    return frequencies[rolloff_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Smapling Frame Spectral roll off featurizer\n",
    "\n",
    "This function computes the frequency range at each sampling frame\"\"\"\n",
    "def computeSpectralRolloffFrequency(stft_magnitude, frequencies, percentile):\n",
    "    \"\"\"Compute the spectral roll off thresholds by using percentile. For percentile calculation\n",
    "    a cumulative sum method is used.\n",
    "    parameters: \n",
    "        stft_magnitude: 2D ndarray containing the magnitudes of the track window's STFT \n",
    "        frequencies: frequencies at the sampling rate and window size\n",
    "        percentile: float [0.001 ~ 0.499], treshold to calculate the rolloff\n",
    "    returns: \"\"\"\n",
    "\n",
    "    # set thresholds. Two-sided percentile needed\n",
    "    # eg percentile = 0.05 -> 1-0.05 = 0.95 >= 0.0\n",
    "    \n",
    "    if (1-percentile >= percentile): \n",
    "        lower = percentile\n",
    "        upper = 1-percentile\n",
    "    else:\n",
    "        lower = 1-percentile\n",
    "        upper = percentile\n",
    "    \n",
    "    total_energy = np.sum(stft_magnitude, axis=0)\n",
    "    upper_threshold_energy = total_energy*upper\n",
    "    lower_threshold_energy = total_energy*lower\n",
    "\n",
    "    #calculate the cumulative energy along frequency bins\n",
    "    cumulative_energy = np.cumsum(stft_magnitude, axis=0)\n",
    "\n",
    "    #find freq bin where cumulative energy >= upper threshold, <= low threshold\n",
    "    upper_bin = cumulative_energy >= upper_threshold_energy\n",
    "    lower_bin = cumulative_energy <= lower_threshold_energy\n",
    "    \n",
    "    #argmax, argmin to get the first bins where the cum energy is < upper threshold, and then > lower threshold\n",
    "    upper_indices = np.argmax(upper_bin, axis=0)\n",
    "    lower_indices = np.argmin(lower_bin, axis=0)\n",
    "\n",
    "    #check if any of the bins are \n",
    "    upper_threshold_check = np.any(upper_indices, axis=0)\n",
    "    lower_threshold_check = np.any(lower_indices, axis=0)\n",
    "    # handle cases where threshold is not met, we use lowest and highest freqs\n",
    "    # compute time frames where no frequency bins cross our lower/upper thresholds\n",
    "    upper_indices = np.where(upper_threshold_check, upper_indices, len(frequencies) - 1)\n",
    "    lower_indices = np.where(lower_threshold_check, lower_indices, 0)\n",
    "\n",
    "    # print(f\"total energy: {total_energy}\")\n",
    "    # print(f\"upper_threshold: {upper_threshold_energy}\")\n",
    "    # print(f\"low_threshold: {lower_threshold_energy}\")\n",
    "    return frequencies[upper_indices], frequencies[lower_indices]\n",
    "    \n",
    "\"\"\"this function calls computeSpectralRolloffFrequency in order to trim each piece of the signal. We then calculate the range \n",
    "for the specific interval and average it at the end.\"\"\"\n",
    "def computeFrequencyRange(divided_stft_magnitudes, sampling_rate, percentile=0.05):\n",
    "    \"\"\"frequency range is max-min after trimming off using spectral rolloff\"\"\"\n",
    "    frequencies = np.fft.rfftfreq(2048, d=1/sampling_rate)\n",
    "    frequency_ranges = np.zeros((divided_stft_magnitudes.shape[0],divided_stft_magnitudes.shape[2]))\n",
    "    mean_frequency_range = 0\n",
    "    for i in range(divided_stft_magnitudes.shape[0]):\n",
    "        upper_freq_rolloff, low_freq_rolloff = computeSpectralRolloffFrequency(divided_stft_magnitudes[i], frequencies, percentile)\n",
    "        freq_range_slice = upper_freq_rolloff-low_freq_rolloff\n",
    "        frequency_ranges[i] = freq_range_slice\n",
    "        mean_frequency_range += np.mean(freq_range_slice)\n",
    "    mean_frequency_range /= divided_stft_magnitudes.shape[0]\n",
    "    return frequency_ranges, mean_frequency_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Spectral Bandwidth Calculation\n",
    "    this function is used to compute the spectral bandwidth: it takes in the stft magnitudes, the frequences and the spectral centroid\n",
    "    the bandwidth is the amplitude weighted average of the differences between the spectral components and the centroid\"\"\"\n",
    "def computeSpectralBandwidth(stft_magnitude, frequencies, centroid):\n",
    "    \"\"\"formula: sqrt(mag[i]*(freq[i]-centroid[i])^2)\"\"\"\n",
    "    f_n = frequencies[:, None] #size adjustment \n",
    "    bandwith = np.square(f_n - centroid)\n",
    "    bandwith = stft_magnitude * bandwith\n",
    "    bandwith = np.sqrt(bandwith)\n",
    "    # print(\"this is the stft magnitudes: \", stft_magnitude.shape)\n",
    "    # print(\"this is the stft freq: \", frequencies.shape)\n",
    "    # print(\"this is the stft centroid: \", centroid.shape)\n",
    "    return bandwith\n",
    "    \n",
    "\n",
    "\n",
    "\"\"\"This is where we will comput the mean spectral bandwith\"\"\"\n",
    "def computeSpectralBandwidthMean(divided_stft_magnitudes, spectral_centroids, sampling_rate):\n",
    "    # spectral_centroid, _, _ = computeSpectralCentroidsMean(divided_stft_magnitudes, sampling_rate)\n",
    "    frequencies = np.fft.rfftfreq(2048, d=1/sampling_rate)\n",
    "    x, y = computeSpectralBandwidth(divided_stft_magnitudes[0], frequencies, spec_centroids[0]).shape\n",
    "    spectral_bandwidths = np.zeros((divided_stft_magnitudes.shape[0], x, y))\n",
    "    # spectral_bandwidths = np.zeros((divided_stft_magnitudes.shape[0], spectral_centroids.shape[0]))\n",
    "    total_mean_spectral_bandwidths = 0\n",
    "    mean_spectral_bandwidths = np.zeros((divided_stft_magnitudes.shape[0],1))\n",
    "    for i in range(divided_stft_magnitudes.shape[0]):\n",
    "        spectral_bandwidth_piece = computeSpectralBandwidth(divided_stft_magnitudes[i], frequencies, spectral_centroids[i])\n",
    "        spectral_bandwidths[i] = spectral_bandwidth_piece\n",
    "        mean_spectral_bandwidth_piece = np.mean(spectral_bandwidth_piece)\n",
    "        total_mean_spectral_bandwidths += mean_spectral_bandwidth_piece\n",
    "        mean_spectral_bandwidths[i] = mean_spectral_bandwidth_piece\n",
    "    total_mean_spectral_bandwidths /= divided_stft_magnitudes.shape[0]\n",
    "    return spectral_bandwidths, total_mean_spectral_bandwidths, mean_spectral_bandwidths\n",
    "\n",
    "\n",
    "\n",
    "# Testing Spectral Bandwidth\n",
    "input = \"../audio/cafe_wav.wav\"\n",
    "signal, stft_signal, sampling_rate = processAudio(input, target_sample_rate = 16000)\n",
    "bpm = computeBPM(signal, sampling_rate)\n",
    "\n",
    "divided_signal, win_size, win_count = divideSignal(signal, bpm, sampling_rate, beats_per_win=1)\n",
    "div_stft, div_stft_mag = divideSTFT(divided_signal)\n",
    "\n",
    "spec_centroids, total_mean_spec, mean_spec_centroids = computeSpectralCentroidsMean(div_stft_mag, sampling_rate)\n",
    "\n",
    "spec_b, tot_mean_b, mean_b = computeSpectralBandwidthMean(div_stft_mag, spec_centroids, sampling_rate)\n",
    "# out1 = computeSpectralBandwidth(div_stft_mag[0], np.fft.rfftfreq(2048, d=1/sampling_rate), spec_centroids[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mhbah\\AppData\\Local\\Temp\\ipykernel_54616\\2354857911.py:8: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  signal, sampling_rate = librosa.load(audio_file_path, sr=target_sample_rate, mono=True)\n",
      "c:\\Users\\mhbah\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../audio/The Weeknd - Out of Time.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\mhbah\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\librosa\\core\\audio.py:176\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m \u001b[43m__soundfile_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m sf\u001b[38;5;241m.\u001b[39mSoundFileRuntimeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;66;03m# If soundfile failed, try audioread instead\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mhbah\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\librosa\\core\\audio.py:209\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;66;03m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context \u001b[38;5;28;01mas\u001b[39;00m sf_desc:\n",
      "File \u001b[1;32mc:\\Users\\mhbah\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    657\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[1;32m--> 658\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mhbah\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\soundfile.py:1216\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1215\u001b[0m     err \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_error(file_ptr)\n\u001b[1;32m-> 1216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError opening \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode_int \u001b[38;5;241m==\u001b[39m _snd\u001b[38;5;241m.\u001b[39mSFM_WRITE:\n\u001b[0;32m   1218\u001b[0m     \u001b[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[0;32m   1219\u001b[0m     \u001b[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m     \u001b[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n",
      "\u001b[1;31mLibsndfileError\u001b[0m: Error opening '../audio/The Weeknd - Out of Time.wav': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"testing spectral rolloff, frequency range\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../audio/The Weeknd - Out of Time.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m signal, stft_signal, sampling_rate \u001b[38;5;241m=\u001b[39m \u001b[43mprocessAudio\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_sample_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m bpm \u001b[38;5;241m=\u001b[39m computeBPM(signal, sampling_rate)\n\u001b[0;32m      6\u001b[0m divided_signal, win_size, win_count \u001b[38;5;241m=\u001b[39m divideSignal(signal, bpm, sampling_rate, beats_per_win\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[6], line 8\u001b[0m, in \u001b[0;36mprocessAudio\u001b[1;34m(audio_file_path, target_sample_rate)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocessAudio\u001b[39m(audio_file_path, target_sample_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16000\u001b[39m):\n\u001b[0;32m      6\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"load the audio and sample it at the target rate. \u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m    librosa.load converts the audio file into a time series at the desired sampling rate \"\"\"\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     signal, sampling_rate \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_sample_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmono\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"normalize the amplitude of the signal.\"\"\"\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     signal \u001b[38;5;241m=\u001b[39m signal \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(np\u001b[38;5;241m.\u001b[39mabs(signal))\n",
      "File \u001b[1;32mc:\\Users\\mhbah\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\librosa\\core\\audio.py:184\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPurePath)):\n\u001b[0;32m    181\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    183\u001b[0m     )\n\u001b[1;32m--> 184\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m \u001b[43m__audioread_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mhbah\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\librosa\\util\\decorators.py:59\u001b[0m, in \u001b[0;36mdeprecated.<locals>.__wrapper\u001b[1;34m(func, *args, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Warn the user, and then proceed.\"\"\"\u001b[39;00m\n\u001b[0;32m     51\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mDeprecated as of librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mIt will be removed in librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# Would be 2, but the decorator adds a level\u001b[39;00m\n\u001b[0;32m     58\u001b[0m )\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mhbah\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\librosa\\core\\audio.py:240\u001b[0m, in \u001b[0;36m__audioread_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    237\u001b[0m     reader \u001b[38;5;241m=\u001b[39m path\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;66;03m# If the input was not an audioread object, try to open it\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m     reader \u001b[38;5;241m=\u001b[39m \u001b[43maudioread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m reader \u001b[38;5;28;01mas\u001b[39;00m input_file:\n\u001b[0;32m    243\u001b[0m     sr_native \u001b[38;5;241m=\u001b[39m input_file\u001b[38;5;241m.\u001b[39msamplerate\n",
      "File \u001b[1;32mc:\\Users\\mhbah\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\audioread\\__init__.py:127\u001b[0m, in \u001b[0;36maudio_open\u001b[1;34m(path, backends)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m BackendClass \u001b[38;5;129;01min\u001b[39;00m backends:\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBackendClass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m DecodeError:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mhbah\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\audioread\\rawread.py:59\u001b[0m, in \u001b[0;36mRawAudioFile.__init__\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename):\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m aifc\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../audio/The Weeknd - Out of Time.wav'"
     ]
    }
   ],
   "source": [
    "\"\"\"testing spectral rolloff, frequency range\"\"\"\n",
    "input = \"../audio/The Weeknd - Out of Time.wav\"\n",
    "signal, stft_signal, sampling_rate = processAudio(input, target_sample_rate = 16000)\n",
    "bpm = computeBPM(signal, sampling_rate)\n",
    "\n",
    "divided_signal, win_size, win_count = divideSignal(signal, bpm, sampling_rate, beats_per_win=1)\n",
    "div_stft, div_stft_mag = divideSTFT(divided_signal)\n",
    "\n",
    "# s = div_stft_mag[0]\n",
    "# test_any = np.any(s, axis=0)\n",
    "# freqqs = np.fft.rfftfreq(2048, d=1/sampling_rate)\n",
    "# upper_freq, lower_freq = computeSpectralRolloffFrequency(s, freqqs, 0.05)\n",
    "# freq_range = upper_freq - lower_freq\n",
    "# print(f\"freq range at each time frame is: {freq_range}\")\n",
    "\n",
    "freq_ranges, mean_freq_ranges = computeFrequencyRange(div_stft_mag, sampling_rate)\n",
    "# print(div_stft_mag[0])\n",
    "# roll_95 = computeSpectralRolloffFrequency(s, fr, 0.95)\n",
    "# roll_05 = computeSpectralRolloffFrequency(s, fr, 0.05)\n",
    "# range = roll_95-roll_05\n",
    "\n",
    "# print(range)\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# time_frames = np.arange(roll_95.shape[1])\n",
    "# plt.figure(figsize=(10, 4))\n",
    "# plt.plot(time_frames, roll_95, label=\"95% Rolloff\")\n",
    "# plt.plot(time_frames, roll_05, label=\"5% Rolloff\")\n",
    "# plt.fill_between(time_frames, roll_05, roll_95, alpha=0.2)\n",
    "# plt.title(\"Spectral Rolloff Frequency Range\")\n",
    "# plt.xlabel(\"Time Frame\")\n",
    "# plt.ylabel(\"Frequency (Hz)\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"testing spectral centroid\"\"\"\n",
    "input = \"../audio/The Weeknd - Out of Time.wav\"\n",
    "signal, stft_signal, sampling_rate = processAudio(input, target_sample_rate = 16000)\n",
    "bpm = computeBPM(signal, sampling_rate)\n",
    "\n",
    "divided_signal, win_size, win_count = divideSignal(signal, bpm, sampling_rate, beats_per_win=1)\n",
    "div_stft, div_stft_mag = divideSTFT(divided_signal)\n",
    "# fr= np.fft.rfftfreq(2048, d=1/sampling_rate)\n",
    "\n",
    "# s = div_stft_mag[0]\n",
    "# z = computeSpectralCentroid(s, fr)\n",
    "# t = np.arange(s.shape[1])\n",
    "# plt.figure(figsize=(10, 4))\n",
    "# plt.plot(t, z, label=\"spectral centroid\")\n",
    "# plt.title(\"Spectral Centroid\")\n",
    "# plt.xlabel(\"Time Frame\")\n",
    "# plt.ylabel(\"Centroid (Hz)\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "spectralcentroids, total_spectralcentroid_mean, mean_spectralcentroids = computeSpectralCentroidsMean(div_stft_mag,sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"test windowing, rms, dynamic range\"\"\"\n",
    "# input = \"../audio/Ma Meilleure Ennemie.wav\"\n",
    "input = \"../audio/The Weeknd - Out of Time.wav\"\n",
    "signal, stft_signal, sampling_rate = processAudio(input, target_sample_rate = 16000)\n",
    "# rms = computeRMS(signal)\n",
    "bpm = computeBPM(signal, sampling_rate)\n",
    "\n",
    "# beat_duration = 60/bpm\n",
    "# song_length_seconds = len(signal)/sampling_rate\n",
    "# beat_count = song_length_seconds/beat_duration\n",
    "\n",
    "# print(f\"Song BPM: {bpm}\")\n",
    "# print(f\"Beat duration of the song in seconds: {beat_duration}\")\n",
    "# print(f\"Length of the song: {song_length_seconds}\")\n",
    "# print(f\"Therefore number of beats for the entire song: {beat_count}\")\n",
    "\n",
    "# beats_per_window = 4\n",
    "# window_count = int(np.ceil(beat_count/beats_per_window))\n",
    "# print(f\"The window count is: {window_count}, using {beats_per_window} beats per window. This is calculated through beat_count/beats_per_window rounded up.\")\n",
    "# window_size = int(np.ceil(len(signal)/window_count))\n",
    "# divided_signal_length = window_count * window_size\n",
    "# print(f\"window size at the input sampling rate is therefore: {window_size}\")\n",
    "# print(f\"Therefore the entire new reconstructed audio is as such: {divided_signal_length}, which is longer than the original signal: {len(signal)}\")\n",
    "# signal_size_diff = divided_signal_length - len(signal)\n",
    "# print(f\"the difference between the divided signal length and original signal length is: {signal_size_diff} samples\")\n",
    "# plotSpectrogram(stft_signal, sampling_rate)\n",
    "# print(f\"RMS: {rms}dB, BPM: {bpm}\")\n",
    "\n",
    "divided_signal, win_size, win_count = divideSignal(signal, bpm, sampling_rate, beats_per_win=1)\n",
    "print(f\"The shape of the divided signal is as such: {divided_signal.shape}\")\n",
    "# zero_pad_check = divided_signal[divided_signal.shape[0]-1][divided_signal.shape[1]-signal_size_diff-1:divided_signal.shape[1]-1]\n",
    "# print(f\"Check if zero padding: {zero_pad_check}\")\n",
    "# signal2 = np.arange(10)\n",
    "# div_signal2, _, _ = divideSignal(signal2)\n",
    "# print(div_signal2[][])\n",
    "div_rms, div_rms_mean = computeRMS(divided_signal)\n",
    "# print(f\"div_rms: {div_rms}, div_rms mean: {div_rms_mean}\")\n",
    "# print(div_rms.shape)\n",
    "\n",
    "div_dr, div_dr_mean = computeDynamicRange(divided_signal, div_rms)\n",
    "# print(f\"div_dynamic range: {div_dr}, div_dyanmic range mean: {div_dr_mean}\")\n",
    "# print(div_dr.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spleeter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlibrosa\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspleeter\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mseparator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Separator\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit_and_process_audio\u001b[39m(input_file, target_sample_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16000\u001b[39m):\n\u001b[0;32m     43\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Split audio and process vocals/instrumentals in memory\"\"\"\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spleeter'"
     ]
    }
   ],
   "source": [
    "# \"\"\"@article{spleeter2020,\n",
    "#   doi = {10.21105/joss.02154},\n",
    "#   url = {https://doi.org/10.21105/joss.02154},\n",
    "#   year = {2020},\n",
    "#   publisher = {The Open Journal},\n",
    "#   volume = {5},\n",
    "#   number = {50},\n",
    "#   pages = {2154},\n",
    "#   author = {Romain Hennequin and Anis Khlif and Felix Voituret and Manuel Moussallam},\n",
    "#   title = {Spleeter: a fast and efficient music source separation tool with pre-trained models},\n",
    "#   journal = {Journal of Open Source Software},\n",
    "#   note = {Deezer Research}\n",
    "# }\"\"\"\n",
    "\n",
    "# import os\n",
    "# import subprocess\n",
    "# def splitAudio(input_file):\n",
    "#     output_folder = os.path.splitext(input_file)[0]\n",
    "    \n",
    "#     if not os.path.exists(output_folder):\n",
    "#         os.makedirs(output_folder)\n",
    "\n",
    "#     command = [\n",
    "#         'spleeter', 'separate', \n",
    "#         '-i', input_file, \n",
    "#         '-o', output_folder\n",
    "#     ]\n",
    "\n",
    "#     subprocess.run(command)\n",
    "\n",
    "#     vocal_file = os.path.join(output_folder, 'vocals.wav')\n",
    "#     instrumental_file = os.path.join(output_folder, 'instrumental.wav')\n",
    "\n",
    "#     return vocal_file, instrumental_file\n",
    "\n",
    "\n",
    "# vocal, instrumental = splitAudio(\"audio/katy_wav.wav\")\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "import spleeter as spl\n",
    "\n",
    "from spleeter.separator import Separator\n",
    "\n",
    "def split_and_process_audio(input_file, target_sample_rate=16000):\n",
    "    \"\"\"Split audio and process vocals/instrumentals in memory\"\"\"\n",
    "    # Initialize Spleeter separator (2 stems: vocals + accompaniment)\n",
    "    separator = Separator('spleeter:2stems')\n",
    "    \n",
    "    # Load audio with librosa (already at target sample rate)\n",
    "    waveform, _ = librosa.load(input_file, sr=target_sample_rate, mono=False)\n",
    "    \n",
    "    # Convert to stereo format expected by Spleeter\n",
    "    if waveform.ndim == 1:\n",
    "        waveform = np.array([waveform, waveform])  # Convert mono to stereo\n",
    "    \n",
    "    # Perform separation (returns numpy array)\n",
    "    prediction = separator.separate(waveform)\n",
    "    \n",
    "    # Extract and process vocals\n",
    "    vocal_stereo = prediction['vocals']\n",
    "    vocal_mono = librosa.to_mono(vocal_stereo)\n",
    "    vocal_norm = vocal_mono / np.max(np.abs(vocal_mono))\n",
    "    vocal_stft = librosa.stft(vocal_norm, window='hann')\n",
    "    \n",
    "    # Extract and process instrumental\n",
    "    instrumental_stereo = prediction['accompaniment']\n",
    "    instrumental_mono = librosa.to_mono(instrumental_stereo)\n",
    "    instrumental_norm = instrumental_mono / np.max(np.abs(instrumental_mono))\n",
    "    instrumental_stft = librosa.stft(instrumental_norm, window='hann')\n",
    "    \n",
    "    return (vocal_norm, vocal_stft), (instrumental_norm, instrumental_stft), target_sample_rate\n",
    "\n",
    "# Usage example:\n",
    "vocal_signal, instrumental_signal, sr = split_and_process_audio(\"audio/katy_wav.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 93\u001b[0m\n\u001b[0;32m     84\u001b[0m         instrumental_stft \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mstft(instrumental_signal, window\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhann\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m     87\u001b[0m         (vocal_signal, vocal_stft),\n\u001b[0;32m     88\u001b[0m         (instrumental_signal, instrumental_stft),\n\u001b[0;32m     89\u001b[0m         sr\n\u001b[0;32m     90\u001b[0m     )\n\u001b[1;32m---> 93\u001b[0m vocal, instrumental, sr \u001b[38;5;241m=\u001b[39m \u001b[43msplit_and_process_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../audio/katy_wav.wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 42\u001b[0m, in \u001b[0;36msplit_and_process_audio\u001b[1;34m(input_file, target_sample_rate, model_type)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tempfile\u001b[38;5;241m.\u001b[39mTemporaryDirectory() \u001b[38;5;28;01mas\u001b[39;00m tmp_dir:\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# Run Spleeter separation\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 42\u001b[0m         \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspleeter\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mseparate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-i\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-o\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmp_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-p\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m     54\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpleeter separation failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mdecode()\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     55\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mhbah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py:501\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    498\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[0;32m    499\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m--> 501\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    503\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[1;32mc:\\Users\\mhbah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py:969\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[0;32m    965\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[0;32m    966\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m    967\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m--> 969\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    979\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m    980\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[1;32mc:\\Users\\mhbah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py:1438\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1436\u001b[0m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[0;32m   1437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1438\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1439\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[0;32m   1440\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1441\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1442\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1443\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1444\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1445\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1446\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1447\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1448\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1451\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1452\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1453\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1454\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1455\u001b[0m                          errread, errwrite)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Audio Separation and Processing Pipeline using Spleeter\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "def split_and_process_audio(\n",
    "    input_file: str,\n",
    "    target_sample_rate: int = 16000,\n",
    "    model_type: str = 'spleeter:2stems'\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Separate audio into vocals/instrumentals and process tracks in memory\n",
    "    \n",
    "    Args:\n",
    "        input_file: Path to input audio file\n",
    "        target_sample_rate: Target sample rate for output signals (default: 16000)\n",
    "        model_type: Spleeter model variant (default: 'spleeter:2stems')\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (\n",
    "            (vocal_signal, vocal_stft),\n",
    "            (instrumental_signal, instrumental_stft),\n",
    "            sample_rate\n",
    "        )\n",
    "    \n",
    "    Raises:\n",
    "        FileNotFoundError: If input file doesn't exist\n",
    "        subprocess.CalledProcessError: If Spleeter separation fails\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.exists(input_file):\n",
    "        raise FileNotFoundError(f\"Input file not found: {input_file}\")\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "        # Run Spleeter separation\n",
    "        try:\n",
    "            subprocess.run(\n",
    "                [\n",
    "                    'spleeter', 'separate',\n",
    "                    '-i', input_file,\n",
    "                    '-o', tmp_dir,\n",
    "                ],\n",
    "                check=True,\n",
    "                capture_output=True\n",
    "            )\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            raise RuntimeError(\n",
    "                f\"Spleeter separation failed: {e.stderr.decode().strip()}\"\n",
    "            ) from e\n",
    "\n",
    "        # Construct output paths\n",
    "        base_name = os.path.splitext(os.path.basename(input_file))[0]\n",
    "        vocal_path = os.path.join(tmp_dir, base_name, 'vocals.wav')\n",
    "        instrumental_path = os.path.join(tmp_dir, base_name, 'accompaniment.wav')\n",
    "\n",
    "        # Validate output files\n",
    "        if not os.path.exists(vocal_path):\n",
    "            raise FileNotFoundError(f\"Vocal track not generated at: {vocal_path}\")\n",
    "        if not os.path.exists(instrumental_path):\n",
    "            raise FileNotFoundError(f\"Instrumental track not generated at: {instrumental_path}\")\n",
    "\n",
    "        # Process vocal track\n",
    "        vocal_signal, sr = librosa.load(\n",
    "            vocal_path,\n",
    "            sr=target_sample_rate,\n",
    "            mono=True\n",
    "        )\n",
    "        vocal_signal = librosa.util.normalize(vocal_signal)\n",
    "        vocal_stft = librosa.stft(vocal_signal, window='hann')\n",
    "\n",
    "        # Process instrumental track\n",
    "        instrumental_signal, _ = librosa.load(\n",
    "            instrumental_path,\n",
    "            sr=target_sample_rate,\n",
    "            mono=True\n",
    "        )\n",
    "        instrumental_signal = librosa.util.normalize(instrumental_signal)\n",
    "        instrumental_stft = librosa.stft(instrumental_signal, window='hann')\n",
    "\n",
    "    return (\n",
    "        (vocal_signal, vocal_stft),\n",
    "        (instrumental_signal, instrumental_stft),\n",
    "        sr\n",
    "    )\n",
    "\n",
    "\n",
    "vocal, instrumental, sr = split_and_process_audio(\"../audio/katy_wav.wav\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
