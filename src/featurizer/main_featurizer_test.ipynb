{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import tomllib\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import librosa\n",
    "import requests\n",
    "from pydub import AudioSegment\n",
    "from io import BytesIO\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cfg.toml\", \"rb\") as cfg:\n",
    "    keys = tomllib.load(cfg)[\"spotify\"]\n",
    "    c_id = keys[\"client_id\"]\n",
    "    c_secret = keys[\"client_secret\"]\n",
    "    auth_manager = SpotifyClientCredentials(client_id=c_id, client_secret=c_secret)\n",
    "    \n",
    "sp = spotipy.Spotify(auth_manager=auth_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"taken from matthew baleanu and Mohamad-Hassan Bahsoun\n",
    "16khz downsample (default 22.05khz, spotify audio is 44.1khz.)\"\"\"\n",
    "# def downsampleAudio(audio_file_path, target_sample_rate=16000):\n",
    "#     #load the audio and downsample it. \n",
    "#     #librosa.load converts the audio file input (.wav, preferrably) into a time series. \n",
    "#     signal, sampling_rate = librosa.load(audio_file_path, sr=target_sample_rate, mono=True)\n",
    "#     #normalize amplitude of the audio signal\n",
    "#     signal = signal / np.max(np.abs(signal))\n",
    "#     return signal, sampling_rate\n",
    "\n",
    "# #draft preprocessor module. Downsamples and STFTs the audio. \n",
    "# def processAudio(audio_file_path):\n",
    "#     signal, sampling_rate = downsampleAudio(audio_file_path)\n",
    "#     #stft signal for feature computation\n",
    "#     stft_signal = librosa.stft(signal, window='hann')\n",
    "#     return signal, stft_signal\n",
    "\n",
    "\"\"\"default sampling rate set to 16khz as per @bahsoun\"\"\"\n",
    "def processAudio(audio_file_path, target_sample_rate=16000):\n",
    "    \"\"\"load the audio and sample it at the target rate. \n",
    "    librosa.load converts the audio file into a time series at the desired sampling rate \"\"\"\n",
    "    signal, sampling_rate = librosa.load(audio_file_path, sr=target_sample_rate, mono=True)\n",
    "    \"\"\"normalize the amplitude of the signal.\"\"\"\n",
    "    signal = signal / np.max(np.abs(signal))\n",
    "    \"\"\"stft signal for feature computation. probably will be moved. \"\"\"\n",
    "    stft_signal = librosa.stft(signal, window='hann')\n",
    "    return signal, stft_signal, sampling_rate\n",
    "\n",
    "#test function for visualization. Not necessary for any applications, but useful for sanity checking results, I think. \n",
    "def plotSpectrogram(stft_signal, target_sampling_rate):\n",
    "    #adapted from @baleanu\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    #compute the spectrogram power, then to dB\n",
    "    power_spectrogram = np.abs(stft_signal)**2\n",
    "    spectrogram_db = librosa.amplitude_to_db(power_spectrogram, ref=np.max)\n",
    "\n",
    "    #display spectrogram\n",
    "    librosa.display.specshow(spectrogram_db, sr = target_sampling_rate, x_axis='time', y_axis='linear', cmap='viridis')\n",
    "    plt.colorbar(label='Power (dB)')\n",
    "    plt.title('Power Spectrogram')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.show()\n",
    "\n",
    "\"\"\"as suggested by MVM, the signal we divide up the signal into bins and compute a window size in order to get\n",
    "    variance for our feature, this way we can determine how relevant they would be for classification/recommendation.\"\"\"\n",
    "def divideSignal(signal, bpm, sampling_rate, beats_per_win = 4):\n",
    "    \"\"\"process is as such:\n",
    "    1. get global tempo (bpm)\n",
    "    2. convert that to beat segments\n",
    "    3. use it to divide up the song.\"\"\"\n",
    "    beat_duration = 60/bpm\n",
    "    song_length_seconds = len(signal)/sampling_rate\n",
    "    beat_count = song_length_seconds/beat_duration\n",
    "    \n",
    "    \"\"\"once beat count is computed, compute the window size as a fixed multiple of the beat count\n",
    "    Round up division on beat_count/beats_per_win to compute the window count. \n",
    "    To calculate the window size: the length of the signal is seconds * samples, as that is an audio time series. The window size would \n",
    "    therefore be the sample length of len(signal)/window_count rounded up, in order to contain all samples.\"\"\"\n",
    "    window_count = int(np.ceil(beat_count/beats_per_win))\n",
    "    window_size = int(np.ceil(len(signal)/window_count))\n",
    "    \n",
    "    \"\"\"to divide the signal, iterating through the samples is necessary. \n",
    "    This is done through preallocating a numpy array for increased efficiency\n",
    "    and padding at the end for length consistency. Originally performed through cocentration, \n",
    "    reshaping used as new methodfor significantly faster performance and less convoluted code.\n",
    "    (0, max(0, window_count*window_size-len(signal))) is used to calculate how much padding is done. \n",
    "    window_count * window_size gives us the total length of the divided signal.\"\"\"\n",
    "    \n",
    "    divided_signal = np.pad(signal,\n",
    "                            (0, window_count*window_size-len(signal)),\n",
    "                            mode=\"constant\",\n",
    "                            constant_values=0)\n",
    "    \n",
    "    \"\"\"now we must reshape the signal.\"\"\"\n",
    "    divided_signal = divided_signal.reshape(window_count, window_size)\n",
    "    return divided_signal, window_size, window_count\n",
    "\n",
    "# \"\"\"calls the other sub featurizer modules\"\"\"\n",
    "# def featurize(divided_signal, divided_stft_signal, target_sampling_rate):\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from Mohamad-Hassan Bahsoun\n",
    "def computeRMS(signal):\n",
    "    #RMS is the square root of the average of the squared signal. \n",
    "    squared_signal = np.square(signal)\n",
    "    mean_squared = np.mean(squared_signal)\n",
    "    rms = np.sqrt(mean_squared)\n",
    "    #convert RMS to decibels\n",
    "    rms = 20*np.log10(rms)\n",
    "    return rms\n",
    "\n",
    "def computeDynamicRange(signal, rms):\n",
    "    #Dynamic range here is defined as peak - RMS, as peak - min would yield the max. \n",
    "    #decibel conversion in order to avoid computing division, as that ends up being slower. \n",
    "    max_level = 20 *np.log10(np.max(np.abs(signal)))\n",
    "    dynamic_range = max_level - rms\n",
    "    return dynamic_range\n",
    "\n",
    "def computeBPM(signal, target_sample_rate):\n",
    "    \"\"\"temporary BPM calculation is simply done as librosa.feature.bpm. this is because @baleanu code has not been updated to same branch, \n",
    "    and testing of the window division based on BPM relies on this module\n",
    "    this is to be replaced with the real computeBPM function, already implementedby @baleanu\n",
    "    real function signature would actually use a stft_signal\"\"\"\n",
    "    bpm = librosa.feature.tempo(y=signal, sr=target_sample_rate)\n",
    "    return bpm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"divided signal RMS compute\"\"\"\n",
    "def computeRMS(divided_signal):\n",
    "    \"\"\"computes rms and the variance of the RMS\"\"\"\n",
    "    \"\"\"Rms Computed as a vector of the \"\"\"\n",
    "    rms = np.zeros((divided_signal.shape[0], 1))\n",
    "    for i in range(divided_signal.shape[0]):\n",
    "        squared_signal = np.square()\n",
    "        mean_squared = np.mean(squared_signal)\n",
    "        rms[i] = np.sqrt(mean_squared)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the length of the stft signal is: 1025\n",
      "Song BPM: 117.1875\n",
      "Beat duration of the song in seconds: 0.512\n",
      "Length of the song: 148.004\n",
      "Therefore number of beats for the entire song: 289.0703125\n",
      "The window count is: 73, using 4 beats per window. This is calculated through beat_count/beats_per_window rounded up.\n",
      "window size at the input sampling rate is therefore: 32440\n",
      "Therefore the entire new reconstructed audio is as such: 2368120, which is longer than the original signal: 2368064\n",
      "the difference between the divided signal length and original signal length is: 56 samples\n",
      "The shape of the divided signal is as such: (73, 32440)\n",
      "Check if zero padding: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test\"\"\"\n",
    "input = \"../audio/Ma Meilleure Ennemie.wav\"\n",
    "# input = \"../audio/The Weeknd - Out of Time.wav\"\n",
    "signal, stft_signal, sampling_rate = processAudio(input, target_sample_rate = 16000)\n",
    "print(f\"the length of the stft signal is: {len(stft_signal)}\")\n",
    "# rms = computeRMS(signal)\n",
    "bpm = computeBPM(signal, sampling_rate)\n",
    "\n",
    "beat_duration = 60/bpm\n",
    "song_length_seconds = len(signal)/sampling_rate\n",
    "beat_count = song_length_seconds/beat_duration\n",
    "\n",
    "print(f\"Song BPM: {bpm}\")\n",
    "print(f\"Beat duration of the song in seconds: {beat_duration}\")\n",
    "print(f\"Length of the song: {song_length_seconds}\")\n",
    "print(f\"Therefore number of beats for the entire song: {beat_count}\")\n",
    "\n",
    "beats_per_window = 4\n",
    "window_count = int(np.ceil(beat_count/beats_per_window))\n",
    "print(f\"The window count is: {window_count}, using {beats_per_window} beats per window. This is calculated through beat_count/beats_per_window rounded up.\")\n",
    "window_size = int(np.ceil(len(signal)/window_count))\n",
    "divided_signal_length = window_count * window_size\n",
    "print(f\"window size at the input sampling rate is therefore: {window_size}\")\n",
    "print(f\"Therefore the entire new reconstructed audio is as such: {divided_signal_length}, which is longer than the original signal: {len(signal)}\")\n",
    "signal_size_diff = divided_signal_length - len(signal)\n",
    "print(f\"the difference between the divided signal length and original signal length is: {signal_size_diff} samples\")\n",
    "# plotSpectrogram(stft_signal, sampling_rate)\n",
    "# print(f\"RMS: {rms}dB, BPM: {bpm}\")\n",
    "\n",
    "divided_signal,_, _ = divideSignal(signal, bpm, sampling_rate)\n",
    "print(f\"The shape of the divided signal is as such: {divided_signal.shape}\")\n",
    "zero_pad_check = divided_signal[divided_signal.shape[0]-1][divided_signal.shape[1]-signal_size_diff-1:divided_signal.shape[1]-1]\n",
    "print(f\"Check if zero padding: {zero_pad_check}\")\n",
    "# signal2 = np.arange(10)\n",
    "# div_signal2, _, _ = divideSignal(signal2)\n",
    "# print(div_signal2[][])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 0, 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'using numpy i can make the divisi'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "div_signal = []\n",
    "beats_per_window = 4\n",
    "window_count = int(np.ceil(len(signal)/beats_per_window))\n",
    "print(window_count)\n",
    "i = 0\n",
    "j = 0\n",
    "for v in range(int(np.ceil(len(signal)/beats_per_window))):\n",
    "    # print(i)\n",
    "    j += beats_per_window\n",
    "    if j > len(signal): #insert trailing zeroes\n",
    "        div_signal.append(signal[i:j] + [0] * (j - len(signal)))\n",
    "    else:\n",
    "        div_signal.append(signal[i:j])\n",
    "        i += beats_per_window\n",
    "print(div_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "win_count = 5, beats per win = 4\n",
      "midline: (0, 0)\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[[0 1]\n",
      " [2 3]\n",
      " [4 5]\n",
      " [6 7]\n",
      " [8 9]]\n"
     ]
    }
   ],
   "source": [
    "signal = np.arange(10)\n",
    "win_size = 2\n",
    "win_count = int(np.ceil(signal.shape[0]/win_size))\n",
    "\n",
    "print(f\"win_count = {win_count}, beats per win = {4}\")\n",
    "total_samples = win_count * win_size\n",
    "padded_signal = np.pad(\n",
    "    signal,\n",
    "    (0, total_samples - len(signal)),\n",
    "    mode='constant',\n",
    "    constant_values=0)\n",
    "print(f\"midline: {(0, max(0, total_samples - len(signal)))}\")\n",
    "print(padded_signal)\n",
    "reshaped = padded_signal.reshape(win_count, win_size)\n",
    "print(reshaped)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
