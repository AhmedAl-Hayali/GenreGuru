{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import tomllib\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import librosa\n",
    "import requests\n",
    "from pydub import AudioSegment\n",
    "from io import BytesIO\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cfg.toml\", \"rb\") as cfg:\n",
    "    keys = tomllib.load(cfg)[\"spotify\"]\n",
    "    c_id = keys[\"client_id\"]\n",
    "    c_secret = keys[\"client_secret\"]\n",
    "    auth_manager = SpotifyClientCredentials(client_id=c_id, client_secret=c_secret)\n",
    "    \n",
    "sp = spotipy.Spotify(auth_manager=auth_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"taken from matthew baleanu and Mohamad-Hassan Bahsoun\n",
    "16khz downsample (default 22.05khz, spotify audio is 44.1khz.)\"\"\"\n",
    "# def downsampleAudio(audio_file_path, target_sample_rate=16000):\n",
    "#     #load the audio and downsample it. \n",
    "#     #librosa.load converts the audio file input (.wav, preferrably) into a time series. \n",
    "#     signal, sampling_rate = librosa.load(audio_file_path, sr=target_sample_rate, mono=True)\n",
    "#     #normalize amplitude of the audio signal\n",
    "#     signal = signal / np.max(np.abs(signal))\n",
    "#     return signal, sampling_rate\n",
    "\n",
    "# #draft preprocessor module. Downsamples and STFTs the audio. \n",
    "# def processAudio(audio_file_path):\n",
    "#     signal, sampling_rate = downsampleAudio(audio_file_path)\n",
    "#     #stft signal for feature computation\n",
    "#     stft_signal = librosa.stft(signal, window='hann')\n",
    "#     return signal, stft_signal\n",
    "\n",
    "\"\"\"default sampling rate set to 16khz as per @bahsoun\"\"\"\n",
    "def processAudio(audio_file_path, target_sample_rate=16000):\n",
    "    \"\"\"load the audio and sample it at the target rate. \n",
    "    librosa.load converts the audio file into a time series at the desired sampling rate \"\"\"\n",
    "    signal, sampling_rate = librosa.load(audio_file_path, sr=target_sample_rate, mono=True)\n",
    "    \"\"\"normalize the amplitude of the signal.\"\"\"\n",
    "    signal = signal / np.max(np.abs(signal))\n",
    "    \"\"\"stft signal for feature computation. probably will be moved. \"\"\"\n",
    "    stft_signal = librosa.stft(signal, window='hann')\n",
    "    return signal, stft_signal, sampling_rate\n",
    "\n",
    "#test function for visualization. Not necessary for any applications, but useful for sanity checking results, I think. \n",
    "def plotSpectrogram(stft_signal, target_sampling_rate):\n",
    "    #adapted from @baleanu\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    #compute the spectrogram power, then to dB\n",
    "    power_spectrogram = np.abs(stft_signal)**2\n",
    "    spectrogram_db = librosa.amplitude_to_db(power_spectrogram, ref=np.max)\n",
    "\n",
    "    #display spectrogram\n",
    "    librosa.display.specshow(spectrogram_db, sr = target_sampling_rate, x_axis='time', y_axis='linear', cmap='viridis')\n",
    "    plt.colorbar(label='Power (dB)')\n",
    "    plt.title('Power Spectrogram')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.show()\n",
    "    print(stft_signal.shape)\n",
    "\n",
    "\"\"\"as suggested by MVM, the signal we divide up the signal into bins and compute a window size in order to get\n",
    "    variance for our feature, this way we can determine how relevant they would be for classification/recommendation.\"\"\"\n",
    "def divideSignal(signal, bpm, sampling_rate, beats_per_win = 4):\n",
    "    \"\"\"process is as such:\n",
    "    1. get global tempo (bpm)\n",
    "    2. convert that to beat segments\n",
    "    3. use it to divide up the song.\"\"\"\n",
    "    beat_duration = 60/bpm\n",
    "    song_length_seconds = len(signal)/sampling_rate\n",
    "    beat_count = song_length_seconds/beat_duration\n",
    "    \n",
    "    \"\"\"once beat count is computed, compute the window size as a fixed multiple of the beat count\n",
    "    Round up division on beat_count/beats_per_win to compute the window count. \n",
    "    To calculate the window size: the length of the signal is seconds * samples, as that is an audio time series. The window size would \n",
    "    therefore be the sample length of len(signal)/window_count rounded up, in order to contain all samples.\"\"\"\n",
    "    window_count = int(np.ceil(beat_count/beats_per_win))\n",
    "    window_size = int(np.ceil(len(signal)/window_count))\n",
    "    \n",
    "    \"\"\"to divide the signal we pad the original signal with zeroes at the end until it is of the proper length\n",
    "    for consistency and then reshape it.\"\"\"\n",
    "    \n",
    "    divided_signal = np.pad(signal,\n",
    "                            (0, window_count*window_size-len(signal)),\n",
    "                            mode=\"constant\",\n",
    "                            constant_values=0)\n",
    "    \n",
    "    \"\"\"now we must reshape the signal.\"\"\"\n",
    "    divided_signal = divided_signal.reshape(window_count, window_size)\n",
    "    return divided_signal, window_size, window_count\n",
    "\n",
    "\"\"\"need to STFT invidual pieces\"\"\"\n",
    "def divideSTFT(divided_signal):\n",
    "    \"\"\"sample STFT calculation is necessary in order to perform preallocation for efficiency\"\"\"\n",
    "    x, y = librosa.stft(divided_signal[0]).shape\n",
    "    divided_stft_signal = np.zeros((divided_signal.shape[0], x, y), dtype=np.complex128)\n",
    "    for i in range(divided_signal.shape[0]): divided_stft_signal[i] = librosa.stft(divided_signal[i])\n",
    "    return divided_stft_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from Mohamad-Hassan Bahsoun\n",
    "def computeRMS(signal):\n",
    "    #RMS is the square root of the average of the squared signal. \n",
    "    squared_signal = np.square(signal)\n",
    "    mean_squared = np.mean(squared_signal)\n",
    "    rms = np.sqrt(mean_squared)\n",
    "    #convert RMS to decibels\n",
    "    rms = 20*np.log10(rms)\n",
    "    return rms\n",
    "\n",
    "def computeDynamicRange(signal, rms):\n",
    "    #Dynamic range here is defined as peak - RMS, as peak - min would yield the max. \n",
    "    #decibel conversion in order to avoid computing division, as that ends up being slower. \n",
    "    max_level = 20 *np.log10(np.max(np.abs(signal)))\n",
    "    dynamic_range = max_level - rms\n",
    "    return dynamic_range\n",
    "\n",
    "def computeBPM(signal, target_sample_rate):\n",
    "    \"\"\"temporary BPM calculation is simply done as librosa.feature.bpm. this is because @baleanu code has not been updated to same branch, \n",
    "    and testing of the window division based on BPM relies on this module\n",
    "    this is to be replaced with the real computeBPM function, already implementedby @baleanu\n",
    "    real function signature would actually use a stft_signal\"\"\"\n",
    "    bpm = librosa.feature.tempo(y=signal, sr=target_sample_rate)\n",
    "    return bpm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"divided signal RMS compute\"\"\"\n",
    "def computeRMS(divided_signal):\n",
    "    \"\"\"computes rms over each window, return vector of rms values and average rms\"\"\"\n",
    "    rms = np.zeros((divided_signal.shape[0], 1))\n",
    "    rms_mean = 0\n",
    "    for i in range(divided_signal.shape[0]):\n",
    "        squared_signal = np.square(divided_signal[i])\n",
    "        mean_squared = np.mean(squared_signal)\n",
    "        root_mean_squared = np.sqrt(mean_squared)\n",
    "        \"decibel conversion of the rms portion\"\n",
    "        root_mean_squared = 20*np.log10(root_mean_squared)\n",
    "        rms_mean += root_mean_squared\n",
    "        rms[i] = root_mean_squared\n",
    "    \"\"\"variance calculation\"\"\" \n",
    "    rms_mean /= divided_signal.shape[0]\n",
    "    return rms, rms_mean\n",
    "\n",
    "\"\"\"divided dynamic range compute\"\"\"\n",
    "def computeDynamicRange(divided_signal, divided_rms):\n",
    "    \"\"\"computes dynamic range  of each window and then average dynamic range\"\"\"\n",
    "    dynamic_range = np.zeros((divided_signal.shape[0], 1))\n",
    "    dynamic_range_mean = 0\n",
    "    for i in range(divided_signal.shape[0]):\n",
    "        dynamic_max = 20 *np.log10(np.max(np.abs(divided_signal[i])))\n",
    "        dynamic_range_slice = dynamic_max - divided_rms[i]\n",
    "        dynamic_range[i] = dynamic_range_slice\n",
    "        dynamic_range_mean += dynamic_range_slice\n",
    "    dynamic_range_mean /= divided_signal.shape[0]\n",
    "    return dynamic_range, dynamic_range_mean\n",
    "\n",
    "\n",
    "\"\"\"define a helper function for getSpectralCentroid\"\"\"\n",
    "def computeSpectralCentroid(stft_signal, frequencies):\n",
    "    # compute the magnitude of the stft\n",
    "    x_n = np.abs(stft_signal)\n",
    "    f_n = frequencies[:,None]\n",
    "   \n",
    "    # multiply each frequency bin by the magnitude\n",
    "    numerator = np.sum(f_n * x_n, axis=0)\n",
    "    \n",
    "    denominator = np.sum(x_n, axis=0)\n",
    "\n",
    "    epsilon = 1e-6\n",
    "    denominator = np.where(denominator==0, epsilon, denominator)\n",
    "    \n",
    "    #compute the spectral centroid\n",
    "    spec_c = numerator/denominator\n",
    "    # print(spec_c)\n",
    "    return spec_c\n",
    "\n",
    "\n",
    "\"\"\"frequency range compute, \n",
    "spectral features are necessary for this\n",
    "spectral centroid code adapted from @bahsoun\"\"\"\n",
    "def computeSpectralCentroidsMean(divided_stft_signal, sampling_rate):\n",
    "    \"\"\"spectral centroic calc is: Centroid = (Σₙ₌₀ᴺ⁻¹ [f(n) * x(n)]) / (Σₙ₌₀ᴺ⁻¹ x(n))\n",
    "    np.fft.rfftfreq conputes x(n)*f(n), need to compute spectral centroid over window in each piece of the signal\"\"\"\n",
    "    frequencies = np.fft.rfftfreq(2048, d=1/sampling_rate)\n",
    "    mean_spectral_centroids = np.zeros((divided_stft_signal.shape[0], 1))\n",
    "    spectral_centroids = np.zeros((divided_stft_signal.shape[0], computeSpectralCentroid(divided_stft_signal[0], frequencies).shape[0]))\n",
    "    for i in range(divided_stft_signal.shape[0]):\n",
    "        \"\"\"np.mean in order to average the spectral centroid over the window.\"\"\"\n",
    "        spectral_centroid_piece = computeSpectralCentroid(divided_stft_signal[i], frequencies)\n",
    "        spectral_centroids[i] = spectral_centroid_piece\n",
    "        mean_spectral_centroids[i] = np.mean(spectral_centroid_piece)\n",
    "    return mean_spectral_centroids, spectral_centroids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the divided signal is as such: (335, 10236)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test\"\"\"\n",
    "# input = \"../audio/Ma Meilleure Ennemie.wav\"\n",
    "input = \"../audio/The Weeknd - Out of Time.wav\"\n",
    "signal, stft_signal, sampling_rate = processAudio(input, target_sample_rate = 16000)\n",
    "# rms = computeRMS(signal)\n",
    "bpm = computeBPM(signal, sampling_rate)\n",
    "\n",
    "beat_duration = 60/bpm\n",
    "song_length_seconds = len(signal)/sampling_rate\n",
    "beat_count = song_length_seconds/beat_duration\n",
    "\n",
    "# print(f\"Song BPM: {bpm}\")\n",
    "# print(f\"Beat duration of the song in seconds: {beat_duration}\")\n",
    "# print(f\"Length of the song: {song_length_seconds}\")\n",
    "# print(f\"Therefore number of beats for the entire song: {beat_count}\")\n",
    "\n",
    "# beats_per_window = 4\n",
    "# window_count = int(np.ceil(beat_count/beats_per_window))\n",
    "# print(f\"The window count is: {window_count}, using {beats_per_window} beats per window. This is calculated through beat_count/beats_per_window rounded up.\")\n",
    "# window_size = int(np.ceil(len(signal)/window_count))\n",
    "# divided_signal_length = window_count * window_size\n",
    "# print(f\"window size at the input sampling rate is therefore: {window_size}\")\n",
    "# print(f\"Therefore the entire new reconstructed audio is as such: {divided_signal_length}, which is longer than the original signal: {len(signal)}\")\n",
    "# signal_size_diff = divided_signal_length - len(signal)\n",
    "# print(f\"the difference between the divided signal length and original signal length is: {signal_size_diff} samples\")\n",
    "# plotSpectrogram(stft_signal, sampling_rate)\n",
    "# print(f\"RMS: {rms}dB, BPM: {bpm}\")\n",
    "\n",
    "divided_signal, win_size, win_count = divideSignal(signal, bpm, sampling_rate, beats_per_win=1)\n",
    "print(f\"The shape of the divided signal is as such: {divided_signal.shape}\")\n",
    "# zero_pad_check = divided_signal[divided_signal.shape[0]-1][divided_signal.shape[1]-signal_size_diff-1:divided_signal.shape[1]-1]\n",
    "# print(f\"Check if zero padding: {zero_pad_check}\")\n",
    "# signal2 = np.arange(10)\n",
    "# div_signal2, _, _ = divideSignal(signal2)\n",
    "# print(div_signal2[][])\n",
    "div_rms, div_rms_mean = computeRMS(divided_signal)\n",
    "# print(f\"div_rms: {div_rms}, div_rms mean: {div_rms_mean}\")\n",
    "# print(div_rms.shape)\n",
    "\n",
    "div_dr, div_dr_mean = computeDynamicRange(divided_signal, div_rms)\n",
    "# print(f\"div_dynamic range: {div_dr}, div_dyanmic range mean: {div_dr_mean}\")\n",
    "# print(div_dr.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean spectral centroids shape:(335, 1), spectral centroids shape: (335, 20)\n"
     ]
    }
   ],
   "source": [
    "div_stft = divideSTFT(divided_signal)\n",
    "# print(div_stft.shape)\n",
    "\n",
    "mean_spec_c, spec_c = computeSpectralCentroidsMean(div_stft, sampling_rate)\n",
    "\n",
    "# print(spec_c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
